---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: kserve
    app.kubernetes.io/instance: kserve-controller-manager
    app.kubernetes.io/name: kserve
  name: kserve-controller-manager
  namespace: kubeflow
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: kserve
    app.kubernetes.io/instance: kserve-localmodel-controller-manager
    app.kubernetes.io/name: kserve
  name: kserve-localmodel-controller-manager
  namespace: kubeflow
---
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    app: kserve
    app.kubernetes.io/instance: kserve-localmodelnode-agent
    app.kubernetes.io/name: kserve
  name: kserve-localmodelnode-agent
  namespace: kubeflow
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-leader-election-role
  namespace: kubeflow
rules:
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - create
  - get
  - list
  - update
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - ""
  resources:
  - configmaps/status
  verbs:
  - get
  - update
  - patch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-localmodel-manager-role
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes/status
  verbs:
  - get
  - watch
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  - persistentvolumes
  verbs:
  - create
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - serving.kserve.io
  resources:
  - inferenceservices
  - localmodelnodegroups
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - serving.kserve.io
  resources:
  - localmodelcaches
  - localmodelnodes
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - serving.kserve.io
  resources:
  - localmodelcaches/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - serving.kserve.io
  resources:
  - localmodelnodes/status
  verbs:
  - get
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-localmodelnode-agent-role
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - nodes/status
  verbs:
  - get
  - watch
- apiGroups:
  - batch
  resources:
  - jobs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - batch
  resources:
  - jobs/status
  verbs:
  - get
- apiGroups:
  - serving.kserve.io
  resources:
  - clusterstoragecontainers
  - localmodelnodegroups
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - serving.kserve.io
  resources:
  - localmodelnodes
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - serving.kserve.io
  resources:
  - localmodelnodes/status
  verbs:
  - get
  - patch
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-manager-role
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - create
  - get
  - update
- apiGroups:
  - ""
  resources:
  - events
  - services
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - ""
  resources:
  - namespaces
  - pods
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - secrets
  - serviceaccounts
  verbs:
  - get
- apiGroups:
  - admissionregistration.k8s.io
  resources:
  - mutatingwebhookconfigurations
  - validatingwebhookconfigurations
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps
  resources:
  - deployments
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - gateway.networking.k8s.io
  resources:
  - httproutes
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - keda.sh
  resources:
  - scaledobjects
  - scaledobjects/finalizers
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - keda.sh
  resources:
  - scaledobjects/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - networking.istio.io
  resources:
  - virtualservices
  - virtualservices/finalizers
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - networking.istio.io
  resources:
  - virtualservices/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - opentelemetry.io
  resources:
  - opentelemetrycollectors
  - opentelemetrycollectors/finalizers
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - opentelemetry.io
  resources:
  - opentelemetrycollectors/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - serving.knative.dev
  resources:
  - services
  - services/finalizers
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - serving.knative.dev
  resources:
  - services/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - serving.kserve.io
  resources:
  - clusterservingruntimes
  - clusterservingruntimes/finalizers
  - clusterstoragecontainers
  - inferencegraphs
  - inferencegraphs/finalizers
  - inferenceservices
  - inferenceservices/finalizers
  - servingruntimes
  - servingruntimes/finalizers
  - trainedmodels
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - serving.kserve.io
  resources:
  - clusterservingruntimes/status
  - inferencegraphs/status
  - inferenceservices/status
  - servingruntimes/status
  - trainedmodels/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - serving.kserve.io
  resources:
  - localmodelcaches
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-proxy-role
rules:
- apiGroups:
  - authentication.k8s.io
  resources:
  - tokenreviews
  verbs:
  - create
- apiGroups:
  - authorization.k8s.io
  resources:
  - subjectaccessreviews
  verbs:
  - create
---
aggregationRule:
  clusterRoleSelectors:
  - matchLabels:
      rbac.authorization.kubeflow.org/aggregate-to-kubeflow-kserve-admin: "true"
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-admin: "true"
  name: kubeflow-kserve-admin
rules: []
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-edit: "true"
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-kserve-admin: "true"
  name: kubeflow-kserve-edit
rules:
- apiGroups:
  - serving.kserve.io
  resources:
  - inferencegraphs
  - inferenceservices
  - servingruntimes
  - trainedmodels
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - deletecollection
  - patch
  - update
- apiGroups:
  - serving.knative.dev
  resources:
  - services
  - services/status
  - routes
  - routes/status
  - configurations
  - configurations/status
  - revisions
  - revisions/status
  verbs:
  - get
  - list
  - watch
  - create
  - delete
  - deletecollection
  - patch
  - update
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
    rbac.authorization.kubeflow.org/aggregate-to-kubeflow-view: "true"
  name: kubeflow-kserve-view
rules:
- apiGroups:
  - serving.kserve.io
  resources:
  - inferencegraphs
  - inferenceservices
  - servingruntimes
  - trainedmodels
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - serving.knative.dev
  resources:
  - services
  - services/status
  - routes
  - routes/status
  - configurations
  - configurations/status
  - revisions
  - revisions/status
  verbs:
  - get
  - list
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-leader-election-rolebinding
  namespace: kubeflow
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: kserve-leader-election-role
subjects:
- kind: ServiceAccount
  name: kserve-controller-manager
  namespace: kubeflow
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-localmodel-manager-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kserve-localmodel-manager-role
subjects:
- kind: ServiceAccount
  name: kserve-localmodel-controller-manager
  namespace: kubeflow
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-localmodelnode-agent-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kserve-localmodelnode-agent-role
subjects:
- kind: ServiceAccount
  name: kserve-localmodelnode-agent
  namespace: kubeflow
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-manager-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kserve-manager-role
subjects:
- kind: ServiceAccount
  name: kserve-controller-manager
  namespace: kubeflow
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-proxy-rolebinding
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: kserve-proxy-role
subjects:
- kind: ServiceAccount
  name: kserve-controller-manager
  namespace: kubeflow
---
apiVersion: v1
data:
  _example: "################################\n#                              #\n#
    \   EXAMPLE CONFIGURATION     #\n#                              #\n################################\n\n#
    This block is not actually functional configuration,\n# but serves to illustrate
    the available configuration\n# options and document them in a way that is accessible\n#
    to users that `kubectl edit` this config map.\n#\n# These sample configuration
    options may be copied out of\n# this example block and unindented to be in the
    data block\n# to actually change the configuration.\n\n# ======================================
    EXPLAINERS CONFIGURATION ======================================\n# Example\nexplainers:
    |-\n  {\n      \"art\": {\n          \"image\" : \"kserve/art-explainer\",\n          \"defaultImageVersion\":
    \"latest\"\n      }\n  }\n# Art Explainer runtime configuration\n explainers:
    |-\n   {\n       # Art explainer runtime configuration\n       \"art\": {\n           #
    image contains the default Art explainer serving runtime image uri.\n           \"image\"
    : \"kserve/art-explainer\",\n   \n           # defautltImageVersion contains the
    Art explainer serving runtime default image version.\n           \"defaultImageVersion\":
    \"latest\"\n       }\n   }\n# ====================================== ISVC CONFIGURATION
    ======================================\n# Example - setting custom annotation
    \ \n inferenceService: |-\n   {\n     \"serviceAnnotationDisallowedList\": [\n
    \       \"my.custom.annotation/1\"  \n     ],\n     \"serviceLabelDisallowedList\":
    [\n        \"my.custom.label.1\"  \n     ]\n   }\n# Example - setting custom annotation\ninferenceService:
    |-\n  {\n    # ServiceAnnotationDisallowedList is a list of annotations that are
    not allowed to be propagated to Knative \n    # revisions, which prevents the
    reconciliation loop to be triggered if the annotations is \n    # configured here
    are used.\n    # Default values are:\n    #  \"autoscaling.knative.dev/min-scale\",\n
    \   #  \"autoscaling.knative.dev/max-scale\",\n    #  \"internal.serving.kserve.io/storage-initializer-sourceuri\",\n
    \   #  \"kubectl.kubernetes.io/last-applied-configuration\"\n    # Any new value
    will be appended to the list.\n    \"serviceAnnotationDisallowedList\": [\n      \"my.custom.annotation/1\"
    \ \n    ],\n    # ServiceLabelDisallowedList is a list of labels that are not
    allowed to be propagated to Knative revisions\n    # which prevents the reconciliation
    loop to be triggered if the labels is configured here are used.\n    \"serviceLabelDisallowedList\":
    [\n      \"my.custom.label.1\"  \n    ]\n  } \n# Example - setting custom resource\ninferenceService:
    |-\n  {\n    \"resource\": {\n      \"cpuLimit\": \"1\",\n      \"memoryLimit\":
    \"2Gi\",\n      \"cpuRequest\": \"1\",\n      \"memoryRequest\": \"2Gi\"\n    }\n
    \ }\n# Example - setting custom resource\ninferenceService: |-\n  {\n    # resource
    contains the default resource configuration for the inference service.\n    #
    you can override this configuration by specifying the resources in the inference
    service yaml.\n    # If you want to unbound the resource (limits and requests),
    you can set the value to null or \"\" \n    # or just remove the specific field
    from the config.\n    \"resource\": {\n       # cpuLimit is the limits.cpu to
    set for the inference service.\n       \"cpuLimit\": \"1\",\n\n       # memoryLimit
    is the limits.memory to set for the inference service.\n       \"memoryLimit\":
    \"2Gi\",\n\n       # cpuRequest is the requests.cpu to set for the inference service.\n
    \      \"cpuRequest\": \"1\",\n\n       # memoryRequest is the requests.memory
    to set for the inference service.\n       \"memoryRequest\": \"2Gi\"\n    }\n
    }\n# ====================================== MultiNode CONFIGURATION ======================================\n#
    Example   \nmultiNode: |-\n  {\n    \"customGPUResourceTypeList\": [\n      \"custom.com/gpu\"\n
    \   ]\n  }\n# Example of multinode configuration\nmultiNode: |-\n  {      \n    #
    CustomGPUResourceTypeList is a list of custom GPU resource types intended to identify
    the GPU type of a resource,\n    # not to restrict the user from using a specific
    GPU type.\n    # The MultiNode runtime pod will dynamically add GPU resources
    based on the registered GPU types.\n    \"customGPUResourceTypeList\": [\n      \"custom.com/gpu\"\n
    \   ]\n  }  \n # ====================================== OTelCollector CONFIGURATION
    ======================================\n # Example\n opentelemetryCollector: |-\n
    \  {\n     # scrapeInterval is the interval at which the OpenTelemetry Collector
    will scrape the metrics.\n     \"scrapeInterval\": \"5s\",\n     # metricScalerEndpoint
    is the endpoint from which the KEDA's ScaledObject will scrape the metrics.\n
    \    \"metricScalerEndpoint\": \"keda-otel-scaler.keda.svc:4318\",\n     # metricReceiverEndpoint
    is the endpoint from which the OpenTelemetry Collector will scrape the metrics.\n
    \     \"metricReceiverEndpoint\": \"keda-otel-scaler.keda.svc:4317\"\n   }\n  \n
    # ====================================== STORAGE INITIALIZER CONFIGURATION ======================================\n
    # Example\n storageInitializer: |-\n   {\n       \"image\" : \"kserve/storage-initializer:v0.15.2\",\n
    \      \"memoryRequest\": \"100Mi\",\n       \"memoryLimit\": \"1Gi\",\n       \"cpuRequest\":
    \"100m\",\n       \"cpuLimit\": \"1\",\n       \"caBundleConfigMapName\": \"\",\n
    \      \"caBundleVolumeMountPath\": \"/etc/ssl/custom-certs\",\n       \"enableDirectPvcVolumeMount\":
    false,\n       \"enableModelcar\": false,\n       \"cpuModelcar\": \"10m\",\n
    \      \"memoryModelcar\": \"15Mi\"\n   }\n storageInitializer: |-\n   {\n       #
    image contains the default storage initializer image uri.\n       \"image\" :
    \"kserve/storage-initializer:v0.15.2\",\n       \n       # memoryRequest is the
    requests.memory to set for the storage initializer init container.\n       \"memoryRequest\":
    \"100Mi\",\n   \n        # memoryLimit is the limits.memory to set for the storage
    initializer init container.\n       \"memoryLimit\": \"1Gi\",\n       \n       #
    cpuRequest is the requests.cpu to set for the storage initializer init container.\n
    \      \"cpuRequest\": \"100m\",\n       \n       # cpuLimit is the limits.cpu
    to set for the storage initializer init container.\n       \"cpuLimit\": \"1\",\n
    \  \n       # caBundleConfigMapName is the ConfigMap will be copied to a user
    namespace for the storage initializer init container.\n       \"caBundleConfigMapName\":
    \"\",\n\n       # caBundleVolumeMountPath is the mount point for the configmap
    set by caBundleConfigMapName for the storage initializer init container.\n       \"caBundleVolumeMountPath\":
    \"/etc/ssl/custom-certs\",\n\n       # enableDirectPvcVolumeMount controls whether
    users can mount pvc volumes directly.\n       # if pvc volume is provided in storageuri
    then the pvc volume is directly mounted to /mnt/models in the user container.\n
    \      # rather than symlink it to a shared volume. For more info see https://github.com/kserve/kserve/issues/2737\n
    \      \"enableDirectPvcVolumeMount\": true,\n\n       # enableModelcar enabled
    allows you to directly access an OCI container image by\n       # using a source
    URL with an \"oci://\" schema.\n       \"enableModelcar\": false,\n\n       #
    cpuModelcar is the cpu request and limit that is used for the passive modelcar
    container. It can be\n       # set very low, but should be allowed by any Kubernetes
    LimitRange that might apply.\n       \"cpuModelcar\": \"10m\",\n\n       # cpuModelcar
    is the memory request and limit that is used for the passive modelcar container.
    It can be\n       # set very low, but should be allowed by any Kubernetes LimitRange
    that might apply.\n       \"memoryModelcar\": \"15Mi\",\n\n       # uidModelcar
    is the UID under with which the modelcar process and the main container is running.\n
    \      # Some Kubernetes clusters might require this to be root (0). If not set
    the user id is left untouched (default)\n       \"uidModelcar\": 10\n   }\n \n
    # ====================================== CREDENTIALS ======================================\n
    # Example\n credentials: |-\n   {\n      \"storageSpecSecretName\": \"storage-config\",\n
    \     \"storageSecretNameAnnotation\": \"serving.kserve.io/storageSecretName\",\n
    \     \"gcs\": {\n          \"gcsCredentialFileName\": \"gcloud-application-credentials.json\"\n
    \     },\n      \"s3\": {\n          \"s3AccessKeyIDName\": \"AWS_ACCESS_KEY_ID\",\n
    \         \"s3SecretAccessKeyName\": \"AWS_SECRET_ACCESS_KEY\",\n          \"s3Endpoint\":
    \"\",\n          \"s3UseHttps\": \"\",\n          \"s3Region\": \"\",\n          \"s3VerifySSL\":
    \"\",\n          \"s3UseVirtualBucket\": \"\",\n          \"s3UseAccelerate\":
    \"\",\n          \"s3UseAnonymousCredential\": \"\",\n          \"s3CABundle\":
    \"\"\n      }\n   }\n # This is a global configuration used for downloading models
    from the cloud storage.\n # You can override this configuration by specifying
    the annotations on service account or static secret.\n # https://kserve.github.io/website/master/modelserving/storage/s3/s3/\n
    # For a quick reference about AWS ENV variables:\n # AWS Cli: https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-envvars.html\n
    # Boto: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/configuration.html#using-environment-variables\n
    #\n # The `s3AccessKeyIDName` and `s3SecretAccessKeyName` fields are only used
    from this configmap when static credentials (IAM User Access Key Secret)\n # are
    used as the authentication method for AWS S3.\n # The rest of the fields are used
    in both authentication methods (IAM Role for Service Account & IAM User Access
    Key Secret) if a non-empty value is provided.\n credentials: |-\n   {\n      #
    storageSpecSecretName contains the secret name which has the credentials for downloading
    the model.\n      # This option is used when specifying the storage spec on isvc
    yaml.\n      \"storageSpecSecretName\": \"storage-config\",\n\n      # The annotation
    can be specified on isvc yaml to allow overriding with the secret name reference
    from the annotation value.\n      # When using storageUri the order of the precedence
    is: secret name reference annotation > secret name references from service account\n
    \     # When using storageSpec the order of the precedence is: secret name reference
    annotation > storageSpecSecretName in configmap\n\n      # Configuration for google
    cloud storage\n      \"gcs\": {\n          # gcsCredentialFileName specifies the
    filename of the gcs credential\n          \"gcsCredentialFileName\": \"gcloud-application-credentials.json\"\n
    \     },\n      \n      # Configuration for aws s3 storage. This add the corresponding
    environmental variables to the storage initializer init container.\n      # For
    more info on s3 storage see https://kserve.github.io/website/master/modelserving/storage/s3/s3/\n
    \     \"s3\": {\n          # s3AccessKeyIDName specifies the s3 access key id
    name\n          \"s3AccessKeyIDName\": \"AWS_ACCESS_KEY_ID\",\n   \n          #
    s3SecretAccessKeyName specifies the s3 secret access key name\n          \"s3SecretAccessKeyName\":
    \"AWS_SECRET_ACCESS_KEY\",\n          \n          # s3Endpoint specifies the s3
    endpoint\n          \"s3Endpoint\": \"\",\n          \n          # s3UseHttps
    controls whether to use secure https or unsecure http to download models.\n          #
    Allowed values are 0 and 1.\n          \"s3UseHttps\": \"\",\n   \n          #
    s3Region specifies the region of the bucket.\n          \"s3Region\": \"\",\n
    \         \n          # s3VerifySSL controls whether to verify the tls/ssl certificate.\n
    \         \"s3VerifySSL\": \"\",\n          \n          # s3UseVirtualBucket configures
    whether it is a virtual bucket or not.\n          \"s3UseVirtualBucket\": \"\",\n\n
    \         # s3UseAccelerate configures whether to use transfer acceleration.\n
    \         \"s3UseAccelerate\": \"\",\n           \n          # s3UseAnonymousCredential
    configures whether to use anonymous credentials to download the model or not.\n
    \         \"s3UseAnonymousCredential\": \"\",\n          \n          # s3CABundle
    specifies the path to a certificate bundle to use for HTTPS certificate validation.\n
    \         \"s3CABundle\": \"\"\n      }\n   }\n \n # ======================================
    INGRESS CONFIGURATION ======================================\n # Example\n ingress:
    |-\n   {    \n       \"enableGatewayApi\": false,\n       \"kserveIngressGateway\":
    \"kserve/kserve-ingress-gateway\",\n       \"ingressGateway\" : \"knative-serving/knative-ingress-gateway\",\n
    \      \"localGateway\" : \"knative-serving/knative-local-gateway\",\n       \"localGatewayService\"
    : \"knative-local-gateway.istio-system.svc.cluster.local\",\n       \"ingressDomain\"
    \ : \"example.com\",\n       \"additionalIngressDomains\": [\"additional-example.com\",
    \"additional-example-1.com\"],\n       \"ingressClassName\" : \"istio\",\n       \"domainTemplate\":
    \"{{ .Name }}-{{ .Namespace }}.{{ .IngressDomain }}\",\n       \"urlScheme\":
    \"http\",\n       \"disableIstioVirtualHost\": false,\n       \"disableIngressCreation\":
    false\n   }\n ingress: |-\n   {   \n       # enableGatewayApi specifies whether
    to use Gateway API instead of Ingress to serve external traffic.\n       \"enableGatewayApi\":
    false,\n\n       # KServe implements [Gateway API](https://gateway-api.sigs.k8s.io/)
    to serve external traffic. \n       # By default, KServe configures a default
    gateway to serve external traffic.\n       # But, KServe can be configured to
    use a custom gateway by modifying this configuration.\n       # The gateway should
    be specified in format <gateway namespace>/<gateway name>\n       # NOTE: This
    configuration only applicable for raw deployment.\n       \"kserveIngressGateway\":
    \"kserve/kserve-ingress-gateway\",\n \n       # ingressGateway specifies the ingress
    gateway to serve external traffic.\n       # The gateway should be specified in
    format <gateway namespace>/<gateway name>\n       # NOTE: This configuration only
    applicable for serverless deployment with Istio configured as network layer.\n
    \      \"ingressGateway\" : \"knative-serving/knative-ingress-gateway\",\n \n
    \      # knativeLocalGatewayService specifies the hostname of the Knative's local
    gateway service.\n       # The default KServe configurations are re-using the
    Istio local gateways for Knative. In this case, this\n       # knativeLocalGatewayService
    field can be left unset. When unset, the value of \"localGatewayService\" will
    be used.\n       # However, sometimes it may be better to have local gateways
    specifically for KServe (e.g. when enabling strict mTLS in Istio).\n       # Under
    such setups where KServe is needed to have its own local gateways, the values
    of the \"localGateway\" and\n       # \"localGatewayService\" should point to
    the KServe local gateways. Then, this knativeLocalGatewayService field\n       #
    should point to the Knative's local gateway service.\n       # NOTE: This configuration
    only applicable for serverless deployment with Istio configured as network layer.\n
    \      \"knativeLocalGatewayService\": \"\",\n \n       # localGateway specifies
    the gateway which handles the network traffic within the cluster.\n       # NOTE:
    This configuration only applicable for serverless deployment with Istio configured
    as network layer.\n       \"localGateway\" : \"knative-serving/knative-local-gateway\",\n
    \n       # localGatewayService specifies the hostname of the local gateway service.\n
    \      # NOTE: This configuration only applicable for serverless deployment with
    Istio configured as network layer.\n       \"localGatewayService\" : \"knative-local-gateway.istio-system.svc.cluster.local\",\n
    \n       # ingressDomain specifies the domain name which is used for creating
    the url.\n       # If ingressDomain is empty then example.com is used as default
    domain.\n       # NOTE: This configuration only applicable for raw deployment.\n
    \      \"ingressDomain\"  : \"example.com\",\n\n       # additionalIngressDomains
    specifies the additional domain names which are used for creating the url.\n       \"additionalIngressDomains\":
    [\"additional-example.com\", \"additional-example-1.com\"]\n\n       # ingressClassName
    specifies the ingress controller to use for ingress traffic.\n       # This is
    optional and if omitted the default ingress in the cluster is used.\n       #
    https://kubernetes.io/docs/concepts/services-networking/ingress/#default-ingress-class\n
    \      # NOTE: This configuration only applicable for raw deployment.\n       \"ingressClassName\"
    : \"istio\",\n \n       # domainTemplate specifies the template for generating
    domain/url for each inference service by combining variable from:\n       # Name
    of the inference service  ( {{ .Name}} )\n       # Namespace of the inference
    service ( {{ .Namespace }} )\n       # Annotation of the inference service ( {{
    .Annotations.key }} )\n       # Label of the inference service ( {{ .Labels.key
    }} )\n       # IngressDomain ( {{ .IngressDomain }} )\n       # If domain template
    is empty the default template {{ .Name }}-{{ .Namespace }}.{{ .IngressDomain }}
    is used.\n       # NOTE: This configuration only applicable for raw deployment.\n
    \      \"domainTemplate\": \"{{ .Name }}-{{ .Namespace }}.{{ .IngressDomain }}\",\n
    \n       # urlScheme specifies the url scheme to use for inference service and
    inference graph.\n       # If urlScheme is empty then by default http is used.\n
    \      \"urlScheme\": \"http\",\n \n       # disableIstioVirtualHost controls
    whether to use istio as network layer.\n       # By default istio is used as the
    network layer. When DisableIstioVirtualHost is true, KServe does not\n       #
    create the top level virtual service thus Istio is no longer required for serverless
    mode.\n       # By setting this field to true, user can use other networking layers
    supported by knative.\n       # For more info https://github.com/kserve/kserve/pull/2380,
    https://kserve.github.io/website/master/admin/serverless/kourier_networking/.\n
    \      # NOTE: This configuration is only applicable to serverless deployment.\n
    \      \"disableIstioVirtualHost\": false,\n\n       # disableIngressCreation
    controls whether to disable ingress creation for raw deployment mode.\n       \"disableIngressCreation\":
    false,\n \n       # pathTemplate specifies the template for generating path based
    url for each inference service.\n       # The following variables can be used
    in the template for generating url.\n       # Name of the inference service  (
    {{ .Name}} )\n       # Namespace of the inference service ( {{ .Namespace }} )\n
    \      # For more info https://github.com/kserve/kserve/issues/2257.\n       #
    NOTE: This configuration only applicable to serverless deployment.\n       \"pathTemplate\":
    \"/serving/{{ .Namespace }}/{{ .Name }}\"\n   }\n \n # ======================================
    LOGGER CONFIGURATION ======================================\n # Example\n logger:
    |-\n   {\n       \"image\" : \"kserve/agent:v0.15.2\",\n       \"memoryRequest\":
    \"100Mi\",\n       \"memoryLimit\": \"1Gi\",\n       \"cpuRequest\": \"100m\",\n
    \      \"cpuLimit\": \"1\",\n       \"defaultUrl\": \"http://default-broker\"\n
    \  }\n logger: |-\n   {\n       # image contains the default logger image uri.\n
    \      \"image\" : \"kserve/agent:v0.15.2\",\n   \n       # memoryRequest is the
    requests.memory to set for the logger container.\n       \"memoryRequest\": \"100Mi\",\n
    \      \n       # memoryLimit is the limits.memory to set for the logger container.\n
    \      \"memoryLimit\": \"1Gi\",\n       \n       # cpuRequest is the requests.cpu
    to set for the logger container.\n       \"cpuRequest\": \"100m\",\n       \n
    \      # cpuLimit is the limits.cpu to set for the logger container.\n       \"cpuLimit\":
    \"1\",\n       \n       # defaultUrl specifies the default logger url. If logger
    is not specified in the resource this url is used.\n       \"defaultUrl\": \"http://default-broker\"\n
    \  }\n \n # ====================================== BATCHER CONFIGURATION ======================================\n
    # Example\n batcher: |-\n   {\n       \"image\" : \"kserve/agent:v0.15.2\",\n
    \      \"memoryRequest\": \"1Gi\",\n       \"memoryLimit\": \"1Gi\",\n       \"cpuRequest\":
    \"1\",\n       \"cpuLimit\": \"1\",\n       \"maxBatchSize\": \"32\",\n       \"maxLatency\":
    \"5000\"\n   }\n batcher: |-\n   {\n       # image contains the default batcher
    image uri.\n       \"image\" : \"kserve/agent:v0.15.2\",\n       \n       # memoryRequest
    is the requests.memory to set for the batcher container.\n       \"memoryRequest\":
    \"1Gi\",\n   \n       # memoryLimit is the limits.memory to set for the batcher
    container.\n       \"memoryLimit\": \"1Gi\",\n       \n       # cpuRequest is
    the requests.cpu to set for the batcher container.\n       \"cpuRequest\": \"1\",\n
    \      \n       # cpuLimit is the limits.cpu to set for the batcher container.\n
    \      \"cpuLimit\": \"1\"\n\n       # maxBatchSize is the default maximum batch
    size for batcher.\n       \"maxBatchSize\": \"32\",\n\n       # maxLatency is
    the default maximum latency in milliseconds for batcher to wait and collect the
    batch.\n       \"maxLatency\": \"5000\"\n   }\n \n # ======================================
    AGENT CONFIGURATION ======================================\n # Example\n agent:
    |-\n   {\n       \"image\" : \"kserve/agent:v0.15.2\",\n       \"memoryRequest\":
    \"100Mi\",\n       \"memoryLimit\": \"1Gi\",\n       \"cpuRequest\": \"100m\",\n
    \      \"cpuLimit\": \"1\"\n   }\n agent: |-\n   {\n       # image contains the
    default agent image uri.\n       \"image\" : \"kserve/agent:v0.15.2\",\n   \n
    \      # memoryRequest is the requests.memory to set for the agent container.\n
    \      \"memoryRequest\": \"100Mi\",\n   \n       # memoryLimit is the limits.memory
    to set for the agent container.\n       \"memoryLimit\": \"1Gi\",\n       \n       #
    cpuRequest is the requests.cpu to set for the agent container.\n       \"cpuRequest\":
    \"100m\",\n       \n       # cpuLimit is the limits.cpu to set for the agent container.\n
    \      \"cpuLimit\": \"1\"\n   }\n \n # ======================================
    ROUTER CONFIGURATION ======================================\n # Example\n router:
    |-\n   {\n       \"image\" : \"kserve/router:v0.15.2\",\n       \"memoryRequest\":
    \"100Mi\",\n       \"memoryLimit\": \"1Gi\",\n       \"cpuRequest\": \"100m\",\n
    \      \"cpuLimit\": \"1\",\n       \"headers\": {\n         \"propagate\": []\n
    \      },\n       \"imagePullPolicy\": \"IfNotPresent\",\n       \"imagePullSecrets\":
    [\"docker-secret\"]\n   }\n # router is the implementation of inference graph.\n
    router: |-\n   {\n       # image contains the default router image uri.\n       \"image\"
    : \"kserve/router:v0.15.2\",\n       \n       # memoryRequest is the requests.memory
    to set for the router container.\n       \"memoryRequest\": \"100Mi\",\n       \n
    \      # memoryLimit is the limits.memory to set for the router container.\n       \"memoryLimit\":
    \"1Gi\",\n       \n       # cpuRequest is the requests.cpu to set for the router
    container.\n       \"cpuRequest\": \"100m\",\n       \n       # cpuLimit is the
    limits.cpu to set for the router container.\n       \"cpuLimit\": \"1\",\n       \n
    \      # Propagate the specified headers to all the steps specified in an InferenceGraph.
    \n       # You can either specify the exact header names or use [Golang supported
    regex patterns]\n       # (https://pkg.go.dev/regexp/syntax@go1.21.3#hdr-Syntax)
    to propagate multiple headers.\n       \"headers\": {\n         \"propagate\":
    [\n            \"Authorization\",\n            \"Test-Header-*\",\n            \"*Trace-Id*\"\n
    \        ]\n       }\n\n       # imagePullPolicy specifies when the router image
    should be pulled from registry.\n       \"imagePullPolicy\": \"IfNotPresent\",\n
    \      \n       # # imagePullSecrets specifies the list of secrets to be used
    for pulling the router image from registry.\n       # https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n
    \      \"imagePullSecrets\": [\"docker-secret\"]\n   }\n \n # ======================================
    DEPLOYMENT CONFIGURATION ======================================\n # Example\n
    deploy: |-\n   {\n     \"defaultDeploymentMode\": \"Serverless\"\n   }\n deploy:
    |-\n   {\n     # defaultDeploymentMode specifies the default deployment mode of
    the kserve. The supported values are\n     # Serverless, RawDeployment and ModelMesh.
    Users can override the deployment mode at service level\n     # by adding the
    annotation serving.kserve.io/deploymentMode.For more info on deployment mode visit\n
    \    # Serverless https://kserve.github.io/website/master/admin/serverless/serverless/\n
    \    # RawDeployment https://kserve.github.io/website/master/admin/kubernetes_deployment/\n
    \    # ModelMesh https://kserve.github.io/website/master/admin/modelmesh/\n     \"defaultDeploymentMode\":
    \"Serverless\"\n   }\n\n # ====================================== SERVICE CONFIGURATION
    ======================================\n # Example\n service: |-\n   {\n     \"serviceClusterIPNone\":
    \ false\n   }\n service: |-\n   {\n      # ServiceClusterIPNone is a boolean flag
    to indicate if the service should have a clusterIP set to None.\n      # If the
    DeploymentMode is Raw, the default value for ServiceClusterIPNone if not set is
    false\n      # \"serviceClusterIPNone\":  false\n   }\n\n # ======================================
    METRICS CONFIGURATION ======================================\n # Example\n metricsAggregator:
    |-\n   {\n     \"enableMetricAggregation\": \"false\",\n     \"enablePrometheusScraping\"
    : \"false\"\n   }\n # For more info see https://github.com/kserve/kserve/blob/master/qpext/README.md\n
    metricsAggregator: |-\n   {\n     # enableMetricAggregation configures metric
    aggregation annotation. This adds the annotation serving.kserve.io/enable-metric-aggregation
    to every\n     # service with the specified boolean value. If true enables metric
    aggregation in queue-proxy by setting env vars in the queue proxy container\n
    \    # to configure scraping ports.\n     \"enableMetricAggregation\": \"false\",\n
    \    \n     # enablePrometheusScraping configures metric aggregation annotation.
    This adds the annotation serving.kserve.io/enable-metric-aggregation to every\n
    \    # service with the specified boolean value. If true, prometheus annotations
    are added to the pod. If serving.kserve.io/enable-metric-aggregation is false,\n
    \    # the prometheus port is set with the default prometheus scraping port 9090,
    otherwise the prometheus port annotation is set with the metric aggregation port.\n
    \    \"enablePrometheusScraping\" : \"false\"\n   }\n  \n # ======================================
    LOCALMODEL CONFIGURATION ======================================\n # Example\n
    localModel: |-\n   {\n     \"enabled\": false,\n     # jobNamespace specifies
    the namespace where the download job will be created.\n     \"jobNamespace\":
    \"kserve-localmodel-jobs\",\n     # defaultJobImage specifies the default image
    used for the download job.\n     \"defaultJobImage\" : \"kserve/storage-initializer:v0.15.2\",\n
    \    # Kubernetes modifies the filesystem group ID on the attached volume.\n     \"fsGroup\":
    1000,\n     # TTL for the download job after it is finished.\n     \"jobTTLSecondsAfterFinished\":
    3600,\n     # The frequency at which the local model agent reconciles the local
    models\n     # This is to detect if models are missing from local disk\n     \"reconcilationFrequencyInSecs\":
    60,\n     # This is to disable localmodel pv and pvc management for namespaces
    without isvcs\n     \"disableVolumeManagement\": false\n   }"
  agent: |-
    {
        "image" : "kserve/agent:v0.15.2",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1"
    }
  batcher: |-
    {
        "image" : "kserve/agent:v0.15.2",
        "memoryRequest": "1Gi",
        "memoryLimit": "1Gi",
        "cpuRequest": "1",
        "cpuLimit": "1",
        "maxBatchSize": "32",
        "maxLatency": "5000"
    }
  credentials: |-
    {
       "storageSpecSecretName": "storage-config",
       "storageSecretNameAnnotation": "serving.kserve.io/storageSecretName",
       "gcs": {
           "gcsCredentialFileName": "gcloud-application-credentials.json"
       },
       "s3": {
           "s3AccessKeyIDName": "AWS_ACCESS_KEY_ID",
           "s3SecretAccessKeyName": "AWS_SECRET_ACCESS_KEY",
           "s3Endpoint": "",
           "s3UseHttps": "",
           "s3Region": "",
           "s3VerifySSL": "",
           "s3UseVirtualBucket": "",
           "s3UseAccelerate": "",
           "s3UseAnonymousCredential": "",
           "s3CABundle": ""
       }
    }
  deploy: |-
    {
      "defaultDeploymentMode": "Serverless"
    }
  explainers: |-
    {
        "art": {
            "image" : "kserve/art-explainer",
            "defaultImageVersion": "latest"
        }
    }
  inferenceService: |-
    {
      "resource": {
          "cpuLimit": "1",
          "memoryLimit": "2Gi",
          "cpuRequest": "1",
          "memoryRequest": "2Gi"
        }
    }
  ingress: |-
    {
      "enableGatewayApi": false,
      "kserveIngressGateway": "kserve/kserve-ingress-gateway",
      "ingressGateway": "kubeflow/kubeflow-gateway",
      "localGateway": "knative-serving/knative-local-gateway",
      "localGatewayService": "knative-local-gateway.istio-system.svc.cluster.local",
      "ingressDomain": "example.com",
      "ingressClassName": "istio",
      "domainTemplate": "{{ .Name }}-{{ .Namespace }}.{{ .IngressDomain }}",
      "urlScheme": "http",
      "disableIstioVirtualHost": false,
      "disableIngressCreation": false
    }
  localModel: |-
    {
      "enabled": false,
      "jobNamespace": "kserve-localmodel-jobs",
      "defaultJobImage" : "kserve/storage-initializer:v0.15.2",
      "fsGroup": 1000
    }
  logger: |-
    {
        "image" : "kserve/agent:v0.15.2",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1",
        "defaultUrl": "http://default-broker"
    }
  metricsAggregator: |-
    {
      "enableMetricAggregation": "false",
      "enablePrometheusScraping" : "false"
    }
  opentelemetryCollector: |-
    {
      "scrapeInterval": "5s",
      "metricReceiverEndpoint": "keda-otel-scaler.keda.svc:4317",
      "metricScalerEndpoint": "keda-otel-scaler.keda.svc:4318"
    }
  router: |-
    {
        "image" : "kserve/router:v0.15.2",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1",
        "imagePullPolicy": "IfNotPresent"
    }
  security: |-
    {
      "autoMountServiceAccountToken": true
    }
  storageInitializer: |-
    {
        "image" : "kserve/storage-initializer:v0.15.2",
        "memoryRequest": "100Mi",
        "memoryLimit": "1Gi",
        "cpuRequest": "100m",
        "cpuLimit": "1",
        "caBundleConfigMapName": "",
        "caBundleVolumeMountPath": "/etc/ssl/custom-certs",
        "enableDirectPvcVolumeMount": true,
        "enableModelcar": true,
        "cpuModelcar": "10m",
        "memoryModelcar": "15Mi",
        "uidModelcar": 1010
    }
kind: ConfigMap
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: inferenceservice-config
  namespace: kubeflow
---
apiVersion: v1
kind: Secret
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-webhook-server-secret
  namespace: kubeflow
---
apiVersion: v1
kind: Service
metadata:
  annotations:
    prometheus.io/port: "8443"
    prometheus.io/scheme: https
    prometheus.io/scrape: "true"
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
    control-plane: kserve-controller-manager
    controller-tools.k8s.io: "1.0"
  name: kserve-controller-manager-metrics-service
  namespace: kubeflow
spec:
  ports:
  - name: https
    port: 8443
    targetPort: https
  selector:
    app: kserve
    app.kubernetes.io/name: kserve
    control-plane: kserve-controller-manager
    controller-tools.k8s.io: "1.0"
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
    control-plane: kserve-controller-manager
    controller-tools.k8s.io: "1.0"
  name: kserve-controller-manager-service
  namespace: kubeflow
spec:
  ports:
  - port: 8443
    protocol: TCP
    targetPort: https
  selector:
    app: kserve
    app.kubernetes.io/name: kserve
    control-plane: kserve-controller-manager
    controller-tools.k8s.io: "1.0"
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: kserve-webhook-server-service
  namespace: kubeflow
spec:
  ports:
  - port: 443
    targetPort: webhook-server
  selector:
    app: kserve
    app.kubernetes.io/name: kserve
    control-plane: kserve-controller-manager
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
    control-plane: kserve-controller-manager
    controller-tools.k8s.io: "1.0"
  name: kserve-controller-manager
  namespace: kubeflow
spec:
  selector:
    matchLabels:
      app: kserve
      app.kubernetes.io/name: kserve
      control-plane: kserve-controller-manager
      controller-tools.k8s.io: "1.0"
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: manager
        sidecar.istio.io/inject: "false"
      labels:
        app: kserve
        app.kubernetes.io/name: kserve
        control-plane: kserve-controller-manager
        controller-tools.k8s.io: "1.0"
    spec:
      containers:
      - args:
        - --metrics-addr=127.0.0.1:8080
        - --leader-elect
        command:
        - /manager
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        - name: SECRET_NAME
          value: kserve-webhook-server-cert
        image: kserve/kserve-controller:v0.15.2
        imagePullPolicy: Always
        livenessProbe:
          failureThreshold: 5
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 30
          timeoutSeconds: 5
        name: manager
        ports:
        - containerPort: 9443
          name: webhook-server
          protocol: TCP
        readinessProbe:
          failureThreshold: 5
          httpGet:
            path: /readyz
            port: 8081
          initialDelaySeconds: 30
          periodSeconds: 5
          timeoutSeconds: 5
        resources:
          limits:
            cpu: 100m
            memory: 300Mi
          requests:
            cpu: 100m
            memory: 200Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
        volumeMounts:
        - mountPath: /tmp/k8s-webhook-server/serving-certs
          name: cert
          readOnly: true
      - args:
        - --secure-listen-address=0.0.0.0:8443
        - --upstream=http://127.0.0.1:8080/
        - --logtostderr=true
        - --v=10
        image: quay.io/brancz/kube-rbac-proxy:v0.18.0
        name: kube-rbac-proxy
        ports:
        - containerPort: 8443
          name: https
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: kserve-controller-manager
      terminationGracePeriodSeconds: 10
      volumes:
      - name: cert
        secret:
          defaultMode: 420
          secretName: kserve-webhook-server-cert
---
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
    control-plane: kserve-localmodel-controller-manager
    controller-tools.k8s.io: "1.0"
  name: kserve-localmodel-controller-manager
  namespace: kubeflow
spec:
  selector:
    matchLabels:
      app: kserve
      app.kubernetes.io/name: kserve
      control-plane: kserve-localmodel-controller-manager
      controller-tools.k8s.io: "1.0"
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: manager
      labels:
        app: kserve
        app.kubernetes.io/name: kserve
        control-plane: kserve-localmodel-controller-manager
        controller-tools.k8s.io: "1.0"
    spec:
      containers:
      - command:
        - /manager
        env:
        - name: POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
        image: kserve/kserve-localmodel-controller:v0.15.2
        imagePullPolicy: Always
        name: manager
        resources:
          limits:
            cpu: 100m
            memory: 300Mi
          requests:
            cpu: 100m
            memory: 200Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          privileged: false
          readOnlyRootFilesystem: true
          runAsNonRoot: true
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: kserve-localmodel-controller-manager
      terminationGracePeriodSeconds: 10
---
apiVersion: cert-manager.io/v1
kind: Certificate
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: serving-cert
  namespace: kubeflow
spec:
  commonName: kserve-webhook-server-service.kubeflow.svc
  dnsNames:
  - kserve-webhook-server-service.kubeflow.svc
  issuerRef:
    kind: Issuer
    name: selfsigned-issuer
  secretName: kserve-webhook-server-cert
---
apiVersion: cert-manager.io/v1
kind: Issuer
metadata:
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: selfsigned-issuer
  namespace: kubeflow
spec:
  selfSigned: {}
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-huggingfaceserver
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - args:
    - --model_name={{.Name}}
    env:
    - name: LMCACHE_USE_EXPERIMENTAL
      value: "True"
    image: kserve/huggingfaceserver:v0.15.2
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
    volumeMounts:
    - mountPath: /dev/shm
      name: devshm
  hostIPC: false
  protocolVersions:
  - v2
  - v1
  supportedModelFormats:
  - autoSelect: true
    name: huggingface
    priority: 1
    version: "1"
  volumes:
  - emptyDir:
      medium: Memory
    name: devshm
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-huggingfaceserver-multinode
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - args:
    - --model_name={{.Name}}
    command:
    - bash
    - -c
    - "export MODEL=${MODEL_ID}\nif [[ ! -z ${MODEL_DIR} ]]\nthen\n  export MODEL=${MODEL_DIR}\nfi\n\nexport
      RAY_ADDRESS=${POD_IP}:${RAY_PORT}\nray start --head --disable-usage-stats --include-dashboard
      false \npython ./huggingfaceserver/health_check.py registered_nodes --retries
      200  --probe_name runtime_start\n\npython -m huggingfaceserver --model_dir=${MODEL}
      --tensor-parallel-size=${TENSOR_PARALLEL_SIZE} --pipeline-parallel-size=${PIPELINE_PARALLEL_SIZE}
      $0 $@\n"
    env:
    - name: RAY_PORT
      value: "6379"
    - name: POD_NAMESPACE
      valueFrom:
        fieldRef:
          fieldPath: metadata.namespace
    - name: POD_IP
      valueFrom:
        fieldRef:
          fieldPath: status.podIP
    - name: VLLM_CONFIG_ROOT
      value: /tmp
    - name: HF_HUB_CACHE
      value: /tmp
    image: kserve/huggingfaceserver:v0.15.2-gpu
    livenessProbe:
      exec:
        command:
        - bash
        - -c
        - |
          python ./huggingfaceserver/health_check.py registered_node_and_runtime_health --health_check_url http://localhost:8080 --probe_name head_liveness
      failureThreshold: 2
      periodSeconds: 5
      successThreshold: 1
      timeoutSeconds: 15
    name: kserve-container
    readinessProbe:
      exec:
        command:
        - bash
        - -c
        - |
          python ./huggingfaceserver/health_check.py runtime_health --health_check_url http://localhost:8080 --probe_name head_readiness
      failureThreshold: 2
      periodSeconds: 5
      successThreshold: 1
      timeoutSeconds: 15
    resources:
      limits:
        cpu: "4"
        memory: 12Gi
      requests:
        cpu: "2"
        memory: 6Gi
    startupProbe:
      exec:
        command:
        - bash
        - -c
        - |
          python ./huggingfaceserver/health_check.py registered_node_and_runtime_health --health_check_url http://localhost:8080 --probe_name head_startup
      failureThreshold: 40
      initialDelaySeconds: 60
      periodSeconds: 30
      successThreshold: 1
      timeoutSeconds: 30
    volumeMounts:
    - mountPath: /dev/shm
      name: shm
  protocolVersions:
  - v2
  - v1
  supportedModelFormats:
  - autoSelect: true
    name: huggingface
    priority: 2
    version: "1"
  volumes:
  - emptyDir:
      medium: Memory
      sizeLimit: 3Gi
    name: shm
  workerSpec:
    containers:
    - command:
      - bash
      - -c
      - "export RAY_HEAD_ADDRESS=${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379\nSECONDS=0\n\nwhile
        true; do              \n  if (( SECONDS <= 240 )); then\n    if ray health-check
        --address \"${RAY_HEAD_ADDRESS}\" > /dev/null 2>&1; then\n      echo \"Ray
        Global Control Service(GCS) is ready.\"\n      break\n    fi\n    echo \"$SECONDS
        seconds elapsed: Waiting for Ray Global Control Service(GCS) to be ready.\"\n
        \ else\n    if ray health-check --address \"${RAY_HEAD_ADDRESS}\"; then\n
        \     echo \"Ray Global Control Service(GCS) is ready. Any error messages
        above can be safely ignored.\"\n      break\n    fi\n    echo \"$SECONDS seconds
        elapsed: Still waiting for Ray Global Control Service(GCS) to be ready.\"\n
        \ fi\n\n  sleep 5\ndone\n\necho \"Attempting to connect to Ray cluster at
        $RAY_HEAD_ADDRESS ...\"\nray start --address=\"${RAY_HEAD_ADDRESS}\" --block\n"
      env:
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: POD_NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace
      image: kserve/huggingfaceserver:v0.15.2-gpu
      livenessProbe:
        exec:
          command:
          - bash
          - -c
          - |
            export RAY_ADDRESS=${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local:6379
            python ./huggingfaceserver/health_check.py registered_nodes --probe_name worker_liveness
        failureThreshold: 2
        periodSeconds: 5
        successThreshold: 1
        timeoutSeconds: 15
      name: worker-container
      resources:
        limits:
          cpu: "4"
          memory: 12Gi
        requests:
          cpu: "2"
          memory: 6Gi
      startupProbe:
        exec:
          command:
          - bash
          - -c
          - |
            export RAY_HEAD_NODE=${HEAD_SVC}.${POD_NAMESPACE}.svc.cluster.local
            export RAY_ADDRESS=${RAY_HEAD_NODE}:6379
            python ./huggingfaceserver/health_check.py registered_node_and_runtime_models --runtime_url http://${RAY_HEAD_NODE}:8080/v1/models --probe_name worker_startup
        failureThreshold: 40
        initialDelaySeconds: 60
        periodSeconds: 30
        successThreshold: 1
        timeoutSeconds: 30
      volumeMounts:
      - mountPath: /dev/shm
        name: shm
    pipelineParallelSize: 1
    tensorParallelSize: 1
    volumes:
    - emptyDir:
        medium: Memory
        sizeLimit: 3Gi
      name: shm
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-lgbserver
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    - --nthread=1
    image: kserve/lgbserver:v0.15.2
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
  protocolVersions:
  - v1
  - v2
  supportedModelFormats:
  - autoSelect: true
    name: lightgbm
    priority: 1
    version: "3"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-mlserver
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - env:
    - name: MLSERVER_MODEL_IMPLEMENTATION
      value: '{{.Labels.modelClass}}'
    - name: MLSERVER_HTTP_PORT
      value: "8080"
    - name: MLSERVER_GRPC_PORT
      value: "9000"
    - name: MODELS_DIR
      value: /mnt/models
    image: docker.io/seldonio/mlserver:1.5.0
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
  protocolVersions:
  - v2
  supportedModelFormats:
  - autoSelect: true
    name: sklearn
    priority: 2
    version: "0"
  - autoSelect: true
    name: sklearn
    priority: 2
    version: "1"
  - autoSelect: true
    name: xgboost
    priority: 2
    version: "1"
  - autoSelect: true
    name: xgboost
    priority: 2
    version: "2"
  - autoSelect: true
    name: lightgbm
    priority: 2
    version: "3"
  - autoSelect: true
    name: lightgbm
    priority: 2
    version: "4"
  - autoSelect: true
    name: mlflow
    priority: 1
    version: "1"
  - autoSelect: true
    name: mlflow
    priority: 1
    version: "2"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-paddleserver
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    image: kserve/paddleserver:v0.15.2
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
  protocolVersions:
  - v1
  - v2
  supportedModelFormats:
  - autoSelect: true
    name: paddle
    priority: 1
    version: "2"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-pmmlserver
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    image: kserve/pmmlserver:v0.15.2
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
  protocolVersions:
  - v1
  - v2
  supportedModelFormats:
  - autoSelect: true
    name: pmml
    priority: 1
    version: "3"
  - autoSelect: true
    name: pmml
    priority: 1
    version: "4"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-sklearnserver
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    image: kserve/sklearnserver:v0.15.2
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
  protocolVersions:
  - v1
  - v2
  supportedModelFormats:
  - autoSelect: true
    name: sklearn
    priority: 1
    version: "1"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-tensorflow-serving
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - args:
    - --model_name={{.Name}}
    - --port=9000
    - --rest_api_port=8080
    - --model_base_path=/mnt/models
    - --rest_api_timeout_in_ms=60000
    command:
    - /usr/bin/tensorflow_model_server
    image: tensorflow/serving:2.6.2
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
      runAsUser: 1000
  protocolVersions:
  - v1
  - grpc-v1
  supportedModelFormats:
  - autoSelect: true
    name: tensorflow
    priority: 2
    version: "1"
  - autoSelect: true
    name: tensorflow
    priority: 2
    version: "2"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-torchserve
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8082"
  containers:
  - args:
    - torchserve
    - --start
    - --model-store=/mnt/models/model-store
    - --ts-config=/mnt/models/config/config.properties
    env:
    - name: TS_SERVICE_ENVELOPE
      value: '{{.Labels.serviceEnvelope}}'
    image: pytorch/torchserve-kfs:0.9.0
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
      runAsUser: 1000
  protocolVersions:
  - v1
  - v2
  - grpc-v2
  supportedModelFormats:
  - autoSelect: true
    name: pytorch
    priority: 2
    version: "1"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-tritonserver
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8002"
  containers:
  - args:
    - tritonserver
    - --model-store=/mnt/models
    - --grpc-port=9000
    - --http-port=8080
    - --allow-grpc=true
    - --allow-http=true
    image: nvcr.io/nvidia/tritonserver:23.05-py3
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
      runAsUser: 1000
  protocolVersions:
  - v2
  - grpc-v2
  supportedModelFormats:
  - autoSelect: true
    name: tensorrt
    priority: 1
    version: "8"
  - autoSelect: true
    name: tensorflow
    priority: 1
    version: "1"
  - autoSelect: true
    name: tensorflow
    priority: 1
    version: "2"
  - autoSelect: true
    name: onnx
    priority: 1
    version: "1"
  - name: pytorch
    version: "1"
  - autoSelect: true
    name: triton
    priority: 1
    version: "2"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterServingRuntime
metadata:
  name: kserve-xgbserver
spec:
  annotations:
    prometheus.kserve.io/path: /metrics
    prometheus.kserve.io/port: "8080"
  containers:
  - args:
    - --model_name={{.Name}}
    - --model_dir=/mnt/models
    - --http_port=8080
    - --nthread=1
    image: kserve/xgbserver:v0.15.2
    name: kserve-container
    resources:
      limits:
        cpu: "1"
        memory: 2Gi
      requests:
        cpu: "1"
        memory: 2Gi
    securityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      privileged: false
      runAsNonRoot: true
  protocolVersions:
  - v1
  - v2
  supportedModelFormats:
  - autoSelect: true
    name: xgboost
    priority: 1
    version: "1"
---
apiVersion: serving.kserve.io/v1alpha1
kind: ClusterStorageContainer
metadata:
  name: default
spec:
  container:
    image: kserve/storage-initializer:v0.15.2
    name: storage-initializer
    resources:
      limits:
        cpu: "1"
        memory: 1Gi
      requests:
        cpu: 100m
        memory: 100Mi
  supportedUriFormats:
  - prefix: gs://
  - prefix: s3://
  - prefix: hdfs://
  - prefix: hf://
  - prefix: webhdfs://
  - regex: https://(.+?).blob.core.windows.net/(.+)
  - regex: https://(.+?).file.core.windows.net/(.+)
  - regex: https?://(.+)/(.+)
  workloadType: initContainer
---
apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: kubeflow/serving-cert
  creationTimestamp: null
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: inferenceservice.serving.kserve.io
webhooks:
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    service:
      name: kserve-webhook-server-service
      namespace: kubeflow
      path: /mutate-serving-kserve-io-v1beta1-inferenceservice
  failurePolicy: Fail
  name: inferenceservice.kserve-webhook-server.defaulter
  rules:
  - apiGroups:
    - serving.kserve.io
    apiVersions:
    - v1beta1
    operations:
    - CREATE
    - UPDATE
    resources:
    - inferenceservices
  sideEffects: None
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    service:
      name: kserve-webhook-server-service
      namespace: kubeflow
      path: /mutate-pods
  failurePolicy: Fail
  name: inferenceservice.kserve-webhook-server.pod-mutator
  namespaceSelector:
    matchExpressions:
    - key: control-plane
      operator: DoesNotExist
  objectSelector:
    matchExpressions:
    - key: serving.kserve.io/inferenceservice
      operator: Exists
  reinvocationPolicy: IfNeeded
  rules:
  - apiGroups:
    - ""
    apiVersions:
    - v1
    operations:
    - CREATE
    resources:
    - pods
  sideEffects: None
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: kubeflow/serving-cert
  creationTimestamp: null
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: clusterservingruntime.serving.kserve.io
webhooks:
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    service:
      name: kserve-webhook-server-service
      namespace: kubeflow
      path: /validate-serving-kserve-io-v1alpha1-clusterservingruntime
  failurePolicy: Fail
  name: clusterservingruntime.kserve-webhook-server.validator
  rules:
  - apiGroups:
    - serving.kserve.io
    apiVersions:
    - v1alpha1
    operations:
    - CREATE
    - UPDATE
    resources:
    - clusterservingruntimes
  sideEffects: None
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: kubeflow/serving-cert
  creationTimestamp: null
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: inferencegraph.serving.kserve.io
webhooks:
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    service:
      name: kserve-webhook-server-service
      namespace: kubeflow
      path: /validate-serving-kserve-io-v1alpha1-inferencegraph
  failurePolicy: Fail
  name: inferencegraph.kserve-webhook-server.validator
  rules:
  - apiGroups:
    - serving.kserve.io
    apiVersions:
    - v1alpha1
    operations:
    - CREATE
    - UPDATE
    resources:
    - inferencegraphs
  sideEffects: None
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: kubeflow/serving-cert
  creationTimestamp: null
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: inferenceservice.serving.kserve.io
webhooks:
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    service:
      name: kserve-webhook-server-service
      namespace: kubeflow
      path: /validate-serving-kserve-io-v1beta1-inferenceservice
  failurePolicy: Fail
  name: inferenceservice.kserve-webhook-server.validator
  rules:
  - apiGroups:
    - serving.kserve.io
    apiVersions:
    - v1beta1
    operations:
    - CREATE
    - UPDATE
    resources:
    - inferenceservices
  sideEffects: None
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: kubeflow/serving-cert
  creationTimestamp: null
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: localmodelcache.serving.kserve.io
webhooks:
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    service:
      name: kserve-webhook-server-service
      namespace: kubeflow
      path: /validate-serving-kserve-io-v1alpha1-localmodelcache
  failurePolicy: Fail
  name: localmodelcache.kserve-webhook-server.validator
  rules:
  - apiGroups:
    - serving.kserve.io
    apiVersions:
    - v1alpha1
    operations:
    - CREATE
    - UPDATE
    - DELETE
    resources:
    - localmodelcaches
  sideEffects: None
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: kubeflow/serving-cert
  creationTimestamp: null
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: servingruntime.serving.kserve.io
webhooks:
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    service:
      name: kserve-webhook-server-service
      namespace: kubeflow
      path: /validate-serving-kserve-io-v1alpha1-servingruntime
  failurePolicy: Fail
  name: servingruntime.kserve-webhook-server.validator
  rules:
  - apiGroups:
    - serving.kserve.io
    apiVersions:
    - v1alpha1
    operations:
    - CREATE
    - UPDATE
    resources:
    - servingruntimes
  sideEffects: None
---
apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  annotations:
    cert-manager.io/inject-ca-from: kubeflow/serving-cert
  creationTimestamp: null
  labels:
    app: kserve
    app.kubernetes.io/name: kserve
  name: trainedmodel.serving.kserve.io
webhooks:
- admissionReviewVersions:
  - v1beta1
  clientConfig:
    service:
      name: kserve-webhook-server-service
      namespace: kubeflow
      path: /validate-serving-kserve-io-v1alpha1-trainedmodel
  failurePolicy: Fail
  name: trainedmodel.kserve-webhook-server.validator
  rules:
  - apiGroups:
    - serving.kserve.io
    apiVersions:
    - v1alpha1
    operations:
    - CREATE
    - UPDATE
    resources:
    - trainedmodels
  sideEffects: None
